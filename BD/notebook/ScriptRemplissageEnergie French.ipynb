{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%;\">\n",
    "    <tr style=\"display:none\">\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr style=\"height:3em\">\n",
    "        <td style=\"width:60%;font: bold 2.5em 'Fira Sans', serif;text-align:center\">SCRIPT DE REMPLISSAGE DE BASE   - ENERGIES <br>\n",
    "        Durée d'exécution :  80 sec<br>\n",
    "        <br>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour executer le code il faut tout simplement faire  **\"run all\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Il est important d'avoir les librairies suivantes : \n",
    "- **Pandas** afin de traiter le fichier csv\n",
    "- **Pyodbc** afin de faire du sql et surtout pouvoir se connecter à la base \n",
    "- **Pycountry** convert pour avoir le nom du continent d'un pays\n",
    "- **Time** d'avoir le temps d'exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import time\n",
    "import pycountry_convert as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détails de connexion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'INFO-MSSQL-ETD'\n",
    "database = 'SAE_TEAM55'\n",
    "username = 'etd05'\n",
    "password = 'fqnsbtc4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chemin du fichier csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Z:\\\\Documents\\\\saeTruc\\\\csv\\\\share-elec-by-source.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci est un tableau qui contient les continents et certains indices, il permet par la suite de traiter le cas ou le nom d'un pays est le nom d'un continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = ['North America','South America','Asia','Australia','Africa','Europe','World','Caribbean',\n",
    "        'demographic','Euro','conflict','poor','income','IBRD','IDA','countries','OECD','small','Small',\n",
    "        'Bahamas','Channel','Dem','Rep','Curacao','Hong']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionnaire des activités\n",
    "ce dictionnaire va recenser les différents types d'énergie présents dans le csv en tant que clé. Et en tant que valeur tout simplement la conversion en simple mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = {\n",
    "    'Coal - % electricity': 'Coal',\n",
    "    'Gas - % electricity': 'Gas',\n",
    "    'Hydro - % electricity': 'Hydro',\n",
    "    'Solar - % electricity': 'Solar',\n",
    "    'Wind - % electricity': 'Wind',\n",
    "    'Oil - % electricity': 'Oil',\n",
    "    'Nuclear - % electricity': 'Nuclear',\n",
    "    'Other renewables excluding bioenergy - % electricity': 'Other renewables excluding bioenergy',\n",
    "    'Bioenergy - % electricity': 'Bioenergy'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `get_region_and_country(filename)` va venir regarder si le nom d'un pays est un continent afin d'avoir en tant que nom de pays le continent et le nom de continent le continent. exemple :\n",
    "- AFRICA  ======> country_name = AFRICA & region_name=AFRICA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_and_country(filename):\n",
    "    region_name = filename\n",
    "    country_name = filename\n",
    "    if region_name == \"Cote d'Ivoire\":\n",
    "        country_name = 'Ivory Coast'\n",
    "    if region_name == 'Gambia, The':\n",
    "        country_name = 'Gambia'\n",
    "    for continent in cont:\n",
    "        if continent in region_name:\n",
    "            return region_name, country_name\n",
    "    else:\n",
    "        return region_name, country_name\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cette courte méthode permet de vérifier que la valeur n'est pas nulle ou bien égale à 0 et également prendre que les années supérieures à 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_process_row(value, year):\n",
    "    \"\"\"Vérifie si une ligne doit être traitée.\"\"\"\n",
    "    return pd.notna(value) and value != 0 and year > 1990"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouver une date existante ou bien la crée\n",
    "`get_or_create_date_id(cursor, year)`permet d'avoir une date existante dans la base de données. Si elle n'existe pas elle va l'insérer. Elle retourne l'id de la date récupérer ou crée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_date_id(cursor, year):\n",
    "    date_str = f\"{year}-01-01\"\n",
    "    cursor.execute(\"SELECT DAT_ID FROM T_DATE_DAT WHERE DAT_DATE = ?\", date_str)\n",
    "    row = cursor.fetchone()\n",
    "    if row:\n",
    "        return row[0]\n",
    "    else:\n",
    "        cursor.execute(\"INSERT INTO T_DATE_DAT (DAT_DATE) VALUES (?)\", date_str)\n",
    "        cursor.execute(\"SELECT DAT_ID FROM T_DATE_DAT WHERE DAT_DATE = ?\", date_str)\n",
    "        return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Système d'optimisation\n",
    "Le but d'un chunk est de scinder les données afin d'optimiser leur traitement. Ce processus permet d'éviter de charger tout le csv d'un coup dans la mémoire. Cela optimise grandement le temps d'exécution.\n",
    "`process_chunk(df_chunk, conn, batch_size=100):` permet de créer un chunk qui va faire une taille par défaut de 100 lignes. Et vérifier que la ligne est valide \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(df_chunk, conn, batch_size=100):\n",
    "    cursor = conn.cursor()\n",
    "    batch = []\n",
    "    start_chunk_time = time.time()\n",
    "\n",
    "    for index, row in df_chunk.iterrows():\n",
    "        year = row['Year']\n",
    "        region = row['Entity']\n",
    "        for column, activity in activities.items():\n",
    "            value = row[column]\n",
    "            if should_process_row(value, year):\n",
    "                try:\n",
    "                    value = round(float(value), 6)\n",
    "                except ValueError:\n",
    "                    print(f\"Valeur invalide pour '{column}' à la ligne {index}: {value}\")\n",
    "                    continue\n",
    "\n",
    "                unit = '%'\n",
    "\n",
    "                # Ajouter les données au batch\n",
    "                batch.append((region, year, activity, value, unit))\n",
    "\n",
    "                if len(batch) >= batch_size:\n",
    "                    # Insérer le batch\n",
    "                    insert_batch(batch, cursor)\n",
    "                    batch = []\n",
    "\n",
    "    # Insérer le dernier batch restant\n",
    "    if batch:\n",
    "        insert_batch(batch, cursor)\n",
    "\n",
    "    conn.commit()\n",
    "    end_chunk_time = time.time()\n",
    "    print(f\"Temps de traitement du chunk: {end_chunk_time - start_chunk_time:.2f} secondes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertion des données dans la base de donnée\n",
    "`insert_batch(batch, cursor)` est le coeur du script il va procéder à l'insertion des données :\n",
    "- **La région**\n",
    "- **Le pays**\n",
    "- **Le type d'énergie**\n",
    "- **Obtention de la date**\n",
    "- **Insertion de la donnée**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_batch(batch, cursor):\n",
    "    \n",
    "    for data in batch:\n",
    "        region, year, activity, value, unit = data\n",
    "\n",
    "        try:\n",
    "            region, country_name = get_region_and_country(region)\n",
    "            # Insertion de la région\n",
    "            if region:\n",
    "                cursor.execute(\"\"\"\n",
    "                    IF NOT EXISTS (SELECT 1 FROM T_REGION_REG WHERE REG_NOM = ?)\n",
    "                    BEGIN\n",
    "                        INSERT INTO T_REGION_REG (REG_NOM) VALUES (?)\n",
    "                    END\n",
    "                \"\"\", region, region)\n",
    "                cursor.execute(\"SELECT REG_ID FROM T_REGION_REG WHERE REG_NOM = ?\", region)\n",
    "                region_id = cursor.fetchone()[0]\n",
    "            else:\n",
    "                region_id = None\n",
    "\n",
    "            # Insertion du  pays\n",
    "            if country_name:\n",
    "                cursor.execute(\"\"\"\n",
    "                    IF NOT EXISTS (SELECT 1 FROM T_PAYS_PYS WHERE PYS_NOM = ?)\n",
    "                    BEGIN\n",
    "                        INSERT INTO T_PAYS_PYS (REG_ID, PYS_NOM) VALUES (?, ?)\n",
    "                    END\n",
    "                \"\"\", country_name, region_id, country_name)\n",
    "                cursor.execute(\"SELECT PYS_ID FROM T_PAYS_PYS WHERE PYS_NOM = ?\", country_name)\n",
    "                country_id = cursor.fetchone()[0]\n",
    "            else:\n",
    "                country_id = None\n",
    "\n",
    "\n",
    "            \n",
    "            # Insertion des energies\n",
    "            cursor.execute(\"\"\"\n",
    "                IF NOT EXISTS (SELECT 1 FROM T_ENERGY_EGY WHERE EGY_NOM = ?)\n",
    "                BEGIN\n",
    "                    INSERT INTO T_ENERGY_EGY (EGY_NOM) VALUES (?)\n",
    "                END\n",
    "            \"\"\", (activity, activity))\n",
    "            cursor.execute(\"SELECT EGY_ID FROM T_ENERGY_EGY WHERE EGY_NOM = ?\", (activity,))\n",
    "            EGY_ID = cursor.fetchone()[0]\n",
    "\n",
    "            # Obtenir ou créer DAT_ID\n",
    "            date_id = get_or_create_date_id(cursor, year)\n",
    "\n",
    "            # Insérer les données\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO T_DATA_DTA (PYS_ID, DAT_ID, EGY_ID, DTA_VALEUR, DTA_NOM, DTA_UNITE)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (country_id, date_id, EGY_ID, value, activity, unit))\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Erreur lors de l'insertion des données : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcour du fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, conn, chunksize=1000):\n",
    "    total_chunks = 0\n",
    "    try:\n",
    "        for chunk in pd.read_csv(filename, chunksize=chunksize):\n",
    "            process_chunk(chunk, conn)\n",
    "            total_chunks += 1\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Le fichier est vide.\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Erreur de lecture du fichier CSV : {e}\")\n",
    "\n",
    "    print(f\"Nombre total de chunks traités: {total_chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase de connection et de démarrage\n",
    "C'est un peu comme le main, on va essayer de se connecter à la base de données grâce à toutes les informations saisies. Et démarrer la méthode de parcours du csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        f'SERVER={server};'\n",
    "        f'DATABASE={database};'\n",
    "        f'UID={username};'\n",
    "        f'PWD={password}'\n",
    "    )\n",
    "    print(\"Connexion réussie à la base de données\")\n",
    "except pyodbc.Error as e:\n",
    "    print(f\"Erreur de connexion : {e}\")\n",
    "    exit()\n",
    "\n",
    "# Mesure du temps de traitement\n",
    "start_time = time.time()\n",
    "\n",
    "# Traitement des fichiers\n",
    "process_file(filename, conn)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print('finished')\n",
    "print(f\"Temps total utilisé : {end_time - start_time:.2f} secondes\")\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
